{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of data\n",
    "\n",
    "https://www.bbci.de/competition/iv/desc_2a.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))\n",
    "\n",
    "y_train_valid -= 769\n",
    "y_test -= 769"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 0 ... 3 3 2]\n",
      "Shape of X after trimming: (2115, 22, 500) (2115,)\n",
      "Shape of X after maxpooling: (2115, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (4230, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (8460, 22, 250) (8460,)\n"
     ]
    }
   ],
   "source": [
    "def data_prep(X,y,sub_sample,average,noise):\n",
    "    \n",
    "    total_X = None\n",
    "    total_y = None\n",
    "    \n",
    "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
    "    X = X[:,:,0:500]\n",
    "    print(y)\n",
    "    print('Shape of X after trimming:',X.shape, y.shape)\n",
    "    \n",
    "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
    "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
    "    \n",
    "    \n",
    "    total_X = X_max\n",
    "    total_y = y\n",
    "    print('Shape of X after maxpooling:',total_X.shape)\n",
    "    \n",
    "    # Averaging + noise \n",
    "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
    "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
    "    \n",
    "    total_X = np.vstack((total_X, X_average))\n",
    "    total_y = np.hstack((total_y, y))\n",
    "    print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n",
    "    \n",
    "    # Subsampling\n",
    "    \n",
    "    for i in range(sub_sample):\n",
    "        \n",
    "        X_subsample = X[:, :, i::sub_sample] + \\\n",
    "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
    "            \n",
    "        total_X = np.vstack((total_X, X_subsample))\n",
    "        total_y = np.hstack((total_y, y))\n",
    "        \n",
    "    \n",
    "    print('Shape of X after subsampling and concatenating:',total_X.shape, total_y.shape)\n",
    "    return total_X,total_y\n",
    "\n",
    "\n",
    "X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid, y_train_valid, 2, 2, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X after trimming: (1740, 22, 500) (1740,)\n",
      "Shape of X after maxpooling: (1740, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (3480, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (6960, 22, 250)\n",
      "Shape of X after trimming: (375, 22, 500) (375,)\n",
      "Shape of X after maxpooling: (375, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (750, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (1500, 22, 250)\n",
      "Shape of X after trimming: (443, 22, 500) (443,)\n",
      "Shape of X after maxpooling: (443, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (886, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (1772, 22, 250)\n",
      "Shape of testing set: (1772, 22, 250)\n",
      "Shape of testing labels: (1772,)\n",
      "Shape of training set: (6960, 22, 250)\n",
      "Shape of validation set: (1500, 22, 250)\n",
      "Shape of training labels: (6960,)\n",
      "Shape of validation labels: (1500,)\n",
      "Shape of training labels after categorical conversion: (6960, 4)\n",
      "Shape of validation labels after categorical conversion: (1500, 4)\n",
      "Shape of test labels after categorical conversion: (1772, 4)\n",
      "Shape of training set after adding width info: (6960, 22, 250, 1)\n",
      "Shape of validation set after adding width info: (1500, 22, 250, 1)\n",
      "Shape of test set after adding width info: (1772, 22, 250, 1)\n",
      "Shape of training set after dimension reshaping: (6960, 250, 1, 22)\n",
      "Shape of validation set after dimension reshaping: (1500, 250, 1, 22)\n",
      "Shape of test set after dimension reshaping: (1772, 250, 1, 22)\n"
     ]
    }
   ],
   "source": [
    "ind_valid = np.random.choice(2115, 375, replace=False)\n",
    "ind_train = np.array(list(set(range(2115)).difference(set(ind_valid))))\n",
    "\n",
    "# Creating the training and validation sets using the generated indices\n",
    "(X_train, X_valid) = X_train_valid[ind_train], X_train_valid[ind_valid] \n",
    "(y_train, y_valid) = y_train_valid[ind_train], y_train_valid[ind_valid]\n",
    "\n",
    "\n",
    "## Preprocessing the dataset\n",
    "x_train,y_train = data_prep(X_train,y_train,2,2,True)\n",
    "x_valid,y_valid = data_prep(X_valid,y_valid,2,2,True)\n",
    "X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True)\n",
    "\n",
    "\n",
    "print('Shape of testing set:',X_test_prep.shape)\n",
    "print('Shape of testing labels:',y_test_prep.shape)\n",
    "\n",
    "print('Shape of training set:',x_train.shape)\n",
    "print('Shape of validation set:',x_valid.shape)\n",
    "print('Shape of training labels:',y_train.shape)\n",
    "print('Shape of validation labels:',y_valid.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Converting the labels to categorical variables for multiclass classification\n",
    "y_train = to_categorical(y_train, 4)\n",
    "y_valid = to_categorical(y_valid, 4)\n",
    "y_test = to_categorical(y_test_prep, 4)\n",
    "print('Shape of training labels after categorical conversion:',y_train.shape)\n",
    "print('Shape of validation labels after categorical conversion:',y_valid.shape)\n",
    "print('Shape of test labels after categorical conversion:',y_test.shape)\n",
    "\n",
    "# Adding width of the segment to be 1\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "print('Shape of training set after adding width info:',x_train.shape)\n",
    "print('Shape of validation set after adding width info:',x_valid.shape)\n",
    "print('Shape of test set after adding width info:',x_test.shape)\n",
    "\n",
    "\n",
    "# Reshaping the training and validation dataset\n",
    "x_train = np.swapaxes(x_train, 1,3)\n",
    "x_train = np.swapaxes(x_train, 1,2)\n",
    "x_valid = np.swapaxes(x_valid, 1,3)\n",
    "x_valid = np.swapaxes(x_valid, 1,2)\n",
    "x_test = np.swapaxes(x_test, 1,3)\n",
    "x_test = np.swapaxes(x_test, 1,2)\n",
    "print('Shape of training set after dimension reshaping:',x_train.shape)\n",
    "print('Shape of validation set after dimension reshaping:',x_valid.shape)\n",
    "print('Shape of test set after dimension reshaping:',x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/1703.05051.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_size = 128\n",
    "num_heads = 16\n",
    "dropout  = 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 250, 1, 22)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 250, 1, 50)   11050       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 84, 1, 50)    0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 84, 1, 50)   200         ['max_pooling2d[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 84, 1, 50)    0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 84, 1, 75)    37575       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 28, 1, 75)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 28, 1, 75)   300         ['max_pooling2d_1[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 28, 1, 75)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 28, 1, 100)   75100       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 10, 1, 100)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 10, 1, 100)  400         ['max_pooling2d_2[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 10, 1, 100)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 10, 1, 150)   45150       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 4, 1, 150)   0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 4, 1, 150)   600         ['max_pooling2d_3[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 4, 1, 150)    0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 4, 1, 200)    90200       ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 200)   0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 1, 1, 200)   800         ['max_pooling2d_4[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 1, 1, 200)    0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 1, 1, 200)   1644744     ['dropout_4[0][0]',              \n",
      " dAttention)                                                      'dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " global_max_pooling2d (GlobalMa  (None, 200)         0           ['multi_head_attention[0][0]']   \n",
      " xPooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4)            804         ['global_max_pooling2d[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,906,923\n",
      "Trainable params: 1,905,773\n",
      "Non-trainable params: 1,150\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(250, 1, 22))\n",
    "\n",
    "x = layers.Conv2D(filters=50,  kernel_size=(10,1), activation=\"elu\", padding=\"same\")(inputs)\n",
    "x = layers.MaxPool2D(pool_size=(3,1), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(dropout)(x)\n",
    "x = layers.Conv2D(filters=75,  kernel_size=(10,1), activation=\"elu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(3,1), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(dropout)(x)\n",
    "x = layers.Conv2D(filters=100,  kernel_size=(10,1), activation=\"elu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(3,1), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(dropout)(x)\n",
    "x = layers.Conv2D(filters=150, kernel_size=(3,1), activation=\"elu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(3,1), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(dropout)(x)\n",
    "x = layers.Conv2D(filters=200, kernel_size=(3,1), activation=\"elu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(10,1), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(dropout)(x)\n",
    "\n",
    "x = layers.MultiHeadAttention(\n",
    "    key_dim   = head_size,\n",
    "    num_heads = num_heads,\n",
    "    dropout   = 0.6\n",
    ")(x, x)\n",
    "\n",
    "x = layers.GlobalMaxPool2D()(x)\n",
    "softmax_output = layers.Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs, softmax_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.7269 - accuracy: 0.2464\n",
      "Epoch 1: val_accuracy improved from -inf to 0.28200, saving model to weights.hdf5\n",
      "109/109 [==============================] - 5s 35ms/step - loss: 1.7269 - accuracy: 0.2464 - val_loss: 1.3887 - val_accuracy: 0.2820\n",
      "Epoch 2/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.4441 - accuracy: 0.2614\n",
      "Epoch 2: val_accuracy did not improve from 0.28200\n",
      "109/109 [==============================] - 4s 34ms/step - loss: 1.4441 - accuracy: 0.2614 - val_loss: 1.3796 - val_accuracy: 0.2700\n",
      "Epoch 3/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.3832 - accuracy: 0.2902\n",
      "Epoch 3: val_accuracy did not improve from 0.28200\n",
      "109/109 [==============================] - 4s 34ms/step - loss: 1.3832 - accuracy: 0.2902 - val_loss: 1.4048 - val_accuracy: 0.2447\n",
      "Epoch 4/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.3674 - accuracy: 0.3108\n",
      "Epoch 4: val_accuracy improved from 0.28200 to 0.30600, saving model to weights.hdf5\n",
      "109/109 [==============================] - 4s 34ms/step - loss: 1.3674 - accuracy: 0.3108 - val_loss: 1.3676 - val_accuracy: 0.3060\n",
      "Epoch 5/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.3510 - accuracy: 0.3299\n",
      "Epoch 5: val_accuracy improved from 0.30600 to 0.35067, saving model to weights.hdf5\n",
      "109/109 [==============================] - 4s 34ms/step - loss: 1.3510 - accuracy: 0.3299 - val_loss: 1.3364 - val_accuracy: 0.3507\n",
      "Epoch 6/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.3152 - accuracy: 0.3670\n",
      "Epoch 6: val_accuracy did not improve from 0.35067\n",
      "109/109 [==============================] - 4s 34ms/step - loss: 1.3152 - accuracy: 0.3670 - val_loss: 1.3602 - val_accuracy: 0.2927\n",
      "Epoch 7/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.2772 - accuracy: 0.4029\n",
      "Epoch 7: val_accuracy improved from 0.35067 to 0.36067, saving model to weights.hdf5\n",
      "109/109 [==============================] - 4s 34ms/step - loss: 1.2772 - accuracy: 0.4029 - val_loss: 1.2910 - val_accuracy: 0.3607\n",
      "Epoch 8/100\n",
      " 87/109 [======================>.......] - ETA: 0s - loss: 1.2568 - accuracy: 0.4203"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\joshu\\Client Work\\247 Project\\project_data\\project\\Transformer Final + Test.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/joshu/Client%20Work/247%20Project/project_data/project/Transformer%20Final%20%2B%20Test.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m reduce_lr_loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, min_delta\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/joshu/Client%20Work/247%20Project/project_data/project/Transformer%20Final%20%2B%20Test.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m), metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/joshu/Client%20Work/247%20Project/project_data/project/Transformer%20Final%20%2B%20Test.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m history_transformer \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, validation_data\u001b[39m=\u001b[39;49m(x_valid, y_valid), epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[model_checkpoint_callback])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"weights.hdf5\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics=[\"accuracy\"])\n",
    "history_transformer = model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=100, batch_size=64, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7183 - accuracy: 0.7727\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.9120 - accuracy: 0.7009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.7182916402816772, 0.7726666927337646],\n",
       " [0.9119887351989746, 0.7009029388427734])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid), model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_transformer.history['accuracy'])\n",
    "plt.plot(history_transformer.history['val_accuracy'])\n",
    "plt.title('Transformer model accuracy trajectory')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history_transformer.history['loss'],'o')\n",
    "plt.plot(history_transformer.history['val_loss'],'o')\n",
    "plt.title('Transformer model loss trajectory')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_65 (InputLayer)       [(None, 22, 1000, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_205 (Conv2D)         (None, 22, 976, 40)       1040      \n",
      "                                                                 \n",
      " conv2d_206 (Conv2D)         (None, 1, 933, 40)        1548840   \n",
      "                                                                 \n",
      " average_pooling2d_8 (Averag  (None, 1, 58, 40)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 2320)              0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 4)                 9284      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,559,164\n",
      "Trainable params: 1,559,164\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(22, 1000, 1))\n",
    "x = layers.Conv2D(filters=40, kernel_size=(1,25))(inputs)\n",
    "x = layers.Conv2D(filters=40, kernel_size=(22,44))(x)\n",
    "x = layers.AveragePooling2D(pool_size=(1, 75), strides=(1, 15))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(4, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.7561 - accuracy: 0.3976\n",
      "Epoch 1: val_accuracy improved from -inf to 0.36795, saving model to weights_cnn.hdf5\n",
      "34/34 [==============================] - 86s 3s/step - loss: 1.7561 - accuracy: 0.3976 - val_loss: 1.5722 - val_accuracy: 0.3679\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.3537 - accuracy: 0.4567\n",
      "Epoch 2: val_accuracy improved from 0.36795 to 0.39729, saving model to weights_cnn.hdf5\n",
      "34/34 [==============================] - 86s 3s/step - loss: 1.3537 - accuracy: 0.4567 - val_loss: 1.4057 - val_accuracy: 0.3973\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.1735 - accuracy: 0.5092\n",
      "Epoch 3: val_accuracy improved from 0.39729 to 0.44018, saving model to weights_cnn.hdf5\n",
      "34/34 [==============================] - 86s 3s/step - loss: 1.1735 - accuracy: 0.5092 - val_loss: 1.2549 - val_accuracy: 0.4402\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0670 - accuracy: 0.5560\n",
      "Epoch 4: val_accuracy improved from 0.44018 to 0.45824, saving model to weights_cnn.hdf5\n",
      "34/34 [==============================] - 85s 3s/step - loss: 1.0670 - accuracy: 0.5560 - val_loss: 1.3497 - val_accuracy: 0.4582\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0316 - accuracy: 0.5730\n",
      "Epoch 5: val_accuracy improved from 0.45824 to 0.46501, saving model to weights_cnn.hdf5\n",
      "34/34 [==============================] - 84s 2s/step - loss: 1.0316 - accuracy: 0.5730 - val_loss: 1.2314 - val_accuracy: 0.4650\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0448 - accuracy: 0.5783\n",
      "Epoch 6: val_accuracy did not improve from 0.46501\n",
      "34/34 [==============================] - 84s 2s/step - loss: 1.0448 - accuracy: 0.5783 - val_loss: 1.2816 - val_accuracy: 0.4560\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9802 - accuracy: 0.5976\n",
      "Epoch 7: val_accuracy improved from 0.46501 to 0.48081, saving model to weights_cnn.hdf5\n",
      "34/34 [==============================] - 84s 2s/step - loss: 0.9802 - accuracy: 0.5976 - val_loss: 1.2538 - val_accuracy: 0.4808\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9676 - accuracy: 0.6019\n",
      "Epoch 8: val_accuracy did not improve from 0.48081\n",
      "34/34 [==============================] - 84s 2s/step - loss: 0.9676 - accuracy: 0.6019 - val_loss: 1.2854 - val_accuracy: 0.4695\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.8643 - accuracy: 0.6449\n",
      "Epoch 9: val_accuracy improved from 0.48081 to 0.51016, saving model to weights_cnn.hdf5\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.8643 - accuracy: 0.6449 - val_loss: 1.2462 - val_accuracy: 0.5102\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9457 - accuracy: 0.6265\n",
      "Epoch 10: val_accuracy did not improve from 0.51016\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.9457 - accuracy: 0.6265 - val_loss: 1.2282 - val_accuracy: 0.4673\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9354 - accuracy: 0.6270\n",
      "Epoch 11: val_accuracy did not improve from 0.51016\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.9354 - accuracy: 0.6270 - val_loss: 1.2655 - val_accuracy: 0.4853\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7980 - accuracy: 0.6870\n",
      "Epoch 12: val_accuracy did not improve from 0.51016\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.7980 - accuracy: 0.6870 - val_loss: 1.2302 - val_accuracy: 0.4966\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7504 - accuracy: 0.7054\n",
      "Epoch 13: val_accuracy improved from 0.51016 to 0.53273, saving model to weights_cnn.hdf5\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.7504 - accuracy: 0.7054 - val_loss: 1.2168 - val_accuracy: 0.5327\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.8661 - accuracy: 0.6690\n",
      "Epoch 14: val_accuracy did not improve from 0.53273\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.8661 - accuracy: 0.6690 - val_loss: 1.2803 - val_accuracy: 0.5056\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7302 - accuracy: 0.7187\n",
      "Epoch 15: val_accuracy did not improve from 0.53273\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.7302 - accuracy: 0.7187 - val_loss: 1.2151 - val_accuracy: 0.5214\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6915 - accuracy: 0.7409\n",
      "Epoch 16: val_accuracy did not improve from 0.53273\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.6915 - accuracy: 0.7409 - val_loss: 1.2078 - val_accuracy: 0.5214\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7145 - accuracy: 0.7201\n",
      "Epoch 17: val_accuracy improved from 0.53273 to 0.54402, saving model to weights_cnn.hdf5\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.7145 - accuracy: 0.7201 - val_loss: 1.2138 - val_accuracy: 0.5440\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7291 - accuracy: 0.7149\n",
      "Epoch 18: val_accuracy did not improve from 0.54402\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.7291 - accuracy: 0.7149 - val_loss: 1.2195 - val_accuracy: 0.5124\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6805 - accuracy: 0.7452\n",
      "Epoch 19: val_accuracy did not improve from 0.54402\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.6805 - accuracy: 0.7452 - val_loss: 1.2414 - val_accuracy: 0.5305\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6853 - accuracy: 0.7428\n",
      "Epoch 20: val_accuracy did not improve from 0.54402\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.6853 - accuracy: 0.7428 - val_loss: 1.2373 - val_accuracy: 0.5327\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6290 - accuracy: 0.7560\n",
      "Epoch 21: val_accuracy did not improve from 0.54402\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.6290 - accuracy: 0.7560 - val_loss: 1.2334 - val_accuracy: 0.5418\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7936 - accuracy: 0.6993\n",
      "Epoch 22: val_accuracy did not improve from 0.54402\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.7936 - accuracy: 0.6993 - val_loss: 1.2914 - val_accuracy: 0.5192\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7442 - accuracy: 0.7135\n",
      "Epoch 23: val_accuracy did not improve from 0.54402\n",
      "34/34 [==============================] - 83s 2s/step - loss: 0.7442 - accuracy: 0.7135 - val_loss: 1.3017 - val_accuracy: 0.4898\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6378 - accuracy: 0.7570\n",
      "Epoch 24: val_accuracy did not improve from 0.54402\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.6378 - accuracy: 0.7570 - val_loss: 1.2482 - val_accuracy: 0.5282\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6120 - accuracy: 0.7674\n",
      "Epoch 25: val_accuracy did not improve from 0.54402\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.6120 - accuracy: 0.7674 - val_loss: 1.3692 - val_accuracy: 0.4876\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6272 - accuracy: 0.7598\n",
      "Epoch 26: val_accuracy did not improve from 0.54402\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.6272 - accuracy: 0.7598 - val_loss: 1.2436 - val_accuracy: 0.5305\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6324 - accuracy: 0.7518\n",
      "Epoch 27: val_accuracy did not improve from 0.54402\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.6324 - accuracy: 0.7518 - val_loss: 1.3108 - val_accuracy: 0.5192\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5951 - accuracy: 0.7716\n",
      "Epoch 28: val_accuracy did not improve from 0.54402\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.5951 - accuracy: 0.7716 - val_loss: 1.2951 - val_accuracy: 0.5169\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.7896\n",
      "Epoch 29: val_accuracy did not improve from 0.54402\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.5658 - accuracy: 0.7896 - val_loss: 1.2958 - val_accuracy: 0.5282\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5495 - accuracy: 0.7953\n",
      "Epoch 30: val_accuracy did not improve from 0.54402\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.5495 - accuracy: 0.7953 - val_loss: 1.3140 - val_accuracy: 0.5350\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5954 - accuracy: 0.7735\n",
      "Epoch 31: val_accuracy did not improve from 0.54402\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.5954 - accuracy: 0.7735 - val_loss: 1.2932 - val_accuracy: 0.5260\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5295 - accuracy: 0.8085\n",
      "Epoch 32: val_accuracy did not improve from 0.54402\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.5295 - accuracy: 0.8085 - val_loss: 1.3054 - val_accuracy: 0.5418\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5395 - accuracy: 0.7929\n",
      "Epoch 33: val_accuracy did not improve from 0.54402\n",
      "34/34 [==============================] - 82s 2s/step - loss: 0.5395 - accuracy: 0.7929 - val_loss: 1.3698 - val_accuracy: 0.5237\n",
      "Epoch 34/100\n",
      " 3/34 [=>............................] - ETA: 1:15 - loss: 0.4968 - accuracy: 0.8438"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\joshu\\Client Work\\247 Project\\project_data\\project\\EEG_loading.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/joshu/Client%20Work/247%20Project/project_data/project/EEG_loading.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_checkpoint_callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/joshu/Client%20Work/247%20Project/project_data/project/EEG_loading.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     filepath\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mweights_cnn.hdf5\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/joshu/Client%20Work/247%20Project/project_data/project/EEG_loading.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     save_weights_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/joshu/Client%20Work/247%20Project/project_data/project/EEG_loading.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/joshu/Client%20Work/247%20Project/project_data/project/EEG_loading.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/joshu/Client%20Work/247%20Project/project_data/project/EEG_loading.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m), metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/joshu/Client%20Work/247%20Project/project_data/project/EEG_loading.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_valid, y_train_valid, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[model_checkpoint_callback])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"weights_cnn.hdf5\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-4), metrics=[\"accuracy\"])\n",
    "cnn_history = model.fit(X_train_valid, y_train_valid, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weights_cnn.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 150ms/step - loss: 1.2090 - accuracy: 0.5350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.209013819694519, 0.5349887013435364]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 250, 1, 22)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 250, 1, 25)        5525      \n",
      "                                                                 \n",
      " layer_normalization (LayerN  (None, 250, 1, 25)       50        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 250, 1, 50)        12550     \n",
      "                                                                 \n",
      " layer_normalization_1 (Laye  (None, 250, 1, 50)       100       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 25, 1, 50)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 25, 50)            0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 25, 50)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 25, 128)           91648     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 25, 128)           131584    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 373,557\n",
      "Trainable params: 373,557\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(250, 1, 22))\n",
    "\n",
    "x = layers.Conv2D(filters=25,  kernel_size=(10,1), activation=\"elu\", padding=\"same\")(inputs)\n",
    "x = layers.LayerNormalization()(x)\n",
    "x = layers.Conv2D(filters=50,  kernel_size=(10,1), activation=\"elu\", padding=\"same\")(x)\n",
    "x = layers.LayerNormalization()(x)\n",
    "x = layers.MaxPool2D(pool_size=(10,1))(x)\n",
    "x = layers.Reshape(target_shape=(25,50))(x)\n",
    "x = layers.Dropout(dropout)(x)\n",
    "x = layers.LSTM(128, recurrent_dropout=dropout, return_sequences=True)(x)\n",
    "x = layers.LSTM(256, recurrent_dropout=dropout)(x)\n",
    "x = layers.Dense(4, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.3745 - accuracy: 0.2907\n",
      "Epoch 1: val_accuracy improved from -inf to 0.37400, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 17s 117ms/step - loss: 1.3745 - accuracy: 0.2907 - val_loss: 1.3341 - val_accuracy: 0.3740\n",
      "Epoch 2/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.3261 - accuracy: 0.3657\n",
      "Epoch 2: val_accuracy improved from 0.37400 to 0.38333, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 12s 114ms/step - loss: 1.3261 - accuracy: 0.3657 - val_loss: 1.2829 - val_accuracy: 0.3833\n",
      "Epoch 3/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.2756 - accuracy: 0.4039\n",
      "Epoch 3: val_accuracy improved from 0.38333 to 0.43733, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 1.2756 - accuracy: 0.4039 - val_loss: 1.2074 - val_accuracy: 0.4373\n",
      "Epoch 4/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.2184 - accuracy: 0.4461\n",
      "Epoch 4: val_accuracy improved from 0.43733 to 0.49333, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 13s 116ms/step - loss: 1.2184 - accuracy: 0.4461 - val_loss: 1.1523 - val_accuracy: 0.4933\n",
      "Epoch 5/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.1643 - accuracy: 0.4848\n",
      "Epoch 5: val_accuracy did not improve from 0.49333\n",
      "109/109 [==============================] - 13s 116ms/step - loss: 1.1643 - accuracy: 0.4848 - val_loss: 1.1928 - val_accuracy: 0.4773\n",
      "Epoch 6/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.1304 - accuracy: 0.5124\n",
      "Epoch 6: val_accuracy improved from 0.49333 to 0.50133, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 13s 115ms/step - loss: 1.1304 - accuracy: 0.5124 - val_loss: 1.1346 - val_accuracy: 0.5013\n",
      "Epoch 7/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.0892 - accuracy: 0.5338\n",
      "Epoch 7: val_accuracy improved from 0.50133 to 0.56000, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 12s 114ms/step - loss: 1.0892 - accuracy: 0.5338 - val_loss: 1.0392 - val_accuracy: 0.5600\n",
      "Epoch 8/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.0546 - accuracy: 0.5555\n",
      "Epoch 8: val_accuracy improved from 0.56000 to 0.56733, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 12s 115ms/step - loss: 1.0546 - accuracy: 0.5555 - val_loss: 1.0631 - val_accuracy: 0.5673\n",
      "Epoch 9/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.0260 - accuracy: 0.5764\n",
      "Epoch 9: val_accuracy improved from 0.56733 to 0.57333, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 12s 113ms/step - loss: 1.0260 - accuracy: 0.5764 - val_loss: 1.0375 - val_accuracy: 0.5733\n",
      "Epoch 10/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.0008 - accuracy: 0.5848\n",
      "Epoch 10: val_accuracy improved from 0.57333 to 0.58933, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 12s 115ms/step - loss: 1.0008 - accuracy: 0.5848 - val_loss: 1.0191 - val_accuracy: 0.5893\n",
      "Epoch 11/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.9889 - accuracy: 0.5986\n",
      "Epoch 11: val_accuracy improved from 0.58933 to 0.60067, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 13s 116ms/step - loss: 0.9889 - accuracy: 0.5986 - val_loss: 1.0146 - val_accuracy: 0.6007\n",
      "Epoch 12/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.9657 - accuracy: 0.6080\n",
      "Epoch 12: val_accuracy did not improve from 0.60067\n",
      "109/109 [==============================] - 13s 115ms/step - loss: 0.9657 - accuracy: 0.6080 - val_loss: 1.0422 - val_accuracy: 0.5760\n",
      "Epoch 13/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.9407 - accuracy: 0.6203\n",
      "Epoch 13: val_accuracy improved from 0.60067 to 0.61800, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.9407 - accuracy: 0.6203 - val_loss: 0.9783 - val_accuracy: 0.6180\n",
      "Epoch 14/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.9278 - accuracy: 0.6244\n",
      "Epoch 14: val_accuracy did not improve from 0.61800\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.9278 - accuracy: 0.6244 - val_loss: 0.9877 - val_accuracy: 0.6133\n",
      "Epoch 15/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.9063 - accuracy: 0.6374\n",
      "Epoch 15: val_accuracy did not improve from 0.61800\n",
      "109/109 [==============================] - 13s 120ms/step - loss: 0.9063 - accuracy: 0.6374 - val_loss: 0.9773 - val_accuracy: 0.6100\n",
      "Epoch 16/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.8835 - accuracy: 0.6443\n",
      "Epoch 16: val_accuracy improved from 0.61800 to 0.62533, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.8835 - accuracy: 0.6443 - val_loss: 0.9747 - val_accuracy: 0.6253\n",
      "Epoch 17/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.8844 - accuracy: 0.6414\n",
      "Epoch 17: val_accuracy improved from 0.62533 to 0.62667, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 13s 115ms/step - loss: 0.8844 - accuracy: 0.6414 - val_loss: 0.9680 - val_accuracy: 0.6267\n",
      "Epoch 18/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.8522 - accuracy: 0.6534\n",
      "Epoch 18: val_accuracy did not improve from 0.62667\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.8522 - accuracy: 0.6534 - val_loss: 0.9923 - val_accuracy: 0.6067\n",
      "Epoch 19/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.8430 - accuracy: 0.6665\n",
      "Epoch 19: val_accuracy improved from 0.62667 to 0.64267, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 13s 116ms/step - loss: 0.8430 - accuracy: 0.6665 - val_loss: 0.9520 - val_accuracy: 0.6427\n",
      "Epoch 20/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.8313 - accuracy: 0.6705\n",
      "Epoch 20: val_accuracy did not improve from 0.64267\n",
      "109/109 [==============================] - 13s 118ms/step - loss: 0.8313 - accuracy: 0.6705 - val_loss: 0.9791 - val_accuracy: 0.6173\n",
      "Epoch 21/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.8163 - accuracy: 0.6767\n",
      "Epoch 21: val_accuracy did not improve from 0.64267\n",
      "109/109 [==============================] - 13s 118ms/step - loss: 0.8163 - accuracy: 0.6767 - val_loss: 0.9711 - val_accuracy: 0.6180\n",
      "Epoch 22/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.8046 - accuracy: 0.6770\n",
      "Epoch 22: val_accuracy did not improve from 0.64267\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.8046 - accuracy: 0.6770 - val_loss: 0.9215 - val_accuracy: 0.6407\n",
      "Epoch 23/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.8083 - accuracy: 0.6743\n",
      "Epoch 23: val_accuracy improved from 0.64267 to 0.64467, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 13s 119ms/step - loss: 0.8083 - accuracy: 0.6743 - val_loss: 0.9197 - val_accuracy: 0.6447\n",
      "Epoch 24/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.7707 - accuracy: 0.6977\n",
      "Epoch 24: val_accuracy improved from 0.64467 to 0.64533, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 13s 119ms/step - loss: 0.7707 - accuracy: 0.6977 - val_loss: 0.9283 - val_accuracy: 0.6453\n",
      "Epoch 25/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.7625 - accuracy: 0.6963\n",
      "Epoch 25: val_accuracy did not improve from 0.64533\n",
      "109/109 [==============================] - 13s 118ms/step - loss: 0.7625 - accuracy: 0.6963 - val_loss: 0.9401 - val_accuracy: 0.6453\n",
      "Epoch 26/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.7480 - accuracy: 0.7040\n",
      "Epoch 26: val_accuracy did not improve from 0.64533\n",
      "109/109 [==============================] - 13s 118ms/step - loss: 0.7480 - accuracy: 0.7040 - val_loss: 0.9686 - val_accuracy: 0.6353\n",
      "Epoch 27/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.7424 - accuracy: 0.7023\n",
      "Epoch 27: val_accuracy improved from 0.64533 to 0.65200, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 13s 118ms/step - loss: 0.7424 - accuracy: 0.7023 - val_loss: 0.9485 - val_accuracy: 0.6520\n",
      "Epoch 28/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.7250 - accuracy: 0.7168\n",
      "Epoch 28: val_accuracy improved from 0.65200 to 0.66333, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 13s 121ms/step - loss: 0.7250 - accuracy: 0.7168 - val_loss: 0.9275 - val_accuracy: 0.6633\n",
      "Epoch 29/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.7182 - accuracy: 0.7131\n",
      "Epoch 29: val_accuracy did not improve from 0.66333\n",
      "109/109 [==============================] - 13s 122ms/step - loss: 0.7182 - accuracy: 0.7131 - val_loss: 0.9739 - val_accuracy: 0.6420\n",
      "Epoch 30/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.6905 - accuracy: 0.7250\n",
      "Epoch 30: val_accuracy did not improve from 0.66333\n",
      "109/109 [==============================] - 13s 119ms/step - loss: 0.6905 - accuracy: 0.7250 - val_loss: 0.9804 - val_accuracy: 0.6493\n",
      "Epoch 31/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.6864 - accuracy: 0.7319\n",
      "Epoch 31: val_accuracy did not improve from 0.66333\n",
      "109/109 [==============================] - 13s 118ms/step - loss: 0.6864 - accuracy: 0.7319 - val_loss: 0.9672 - val_accuracy: 0.6500\n",
      "Epoch 32/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.6764 - accuracy: 0.7364\n",
      "Epoch 32: val_accuracy did not improve from 0.66333\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.6764 - accuracy: 0.7364 - val_loss: 1.0038 - val_accuracy: 0.6493\n",
      "Epoch 33/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.6662 - accuracy: 0.7378\n",
      "Epoch 33: val_accuracy did not improve from 0.66333\n",
      "109/109 [==============================] - 13s 120ms/step - loss: 0.6662 - accuracy: 0.7378 - val_loss: 0.9581 - val_accuracy: 0.6587\n",
      "Epoch 34/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.6545 - accuracy: 0.7450\n",
      "Epoch 34: val_accuracy did not improve from 0.66333\n",
      "109/109 [==============================] - 13s 121ms/step - loss: 0.6545 - accuracy: 0.7450 - val_loss: 0.9765 - val_accuracy: 0.6473\n",
      "Epoch 35/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.6451 - accuracy: 0.7490\n",
      "Epoch 35: val_accuracy improved from 0.66333 to 0.66400, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 13s 119ms/step - loss: 0.6451 - accuracy: 0.7490 - val_loss: 0.9532 - val_accuracy: 0.6640\n",
      "Epoch 36/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.6322 - accuracy: 0.7516\n",
      "Epoch 36: val_accuracy did not improve from 0.66400\n",
      "109/109 [==============================] - 13s 121ms/step - loss: 0.6322 - accuracy: 0.7516 - val_loss: 0.9651 - val_accuracy: 0.6633\n",
      "Epoch 37/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.6173 - accuracy: 0.7578\n",
      "Epoch 37: val_accuracy improved from 0.66400 to 0.67267, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 13s 116ms/step - loss: 0.6173 - accuracy: 0.7578 - val_loss: 0.9370 - val_accuracy: 0.6727\n",
      "Epoch 38/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.6137 - accuracy: 0.7533\n",
      "Epoch 38: val_accuracy did not improve from 0.67267\n",
      "109/109 [==============================] - 12s 110ms/step - loss: 0.6137 - accuracy: 0.7533 - val_loss: 0.9993 - val_accuracy: 0.6593\n",
      "Epoch 39/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.5961 - accuracy: 0.7675\n",
      "Epoch 39: val_accuracy did not improve from 0.67267\n",
      "109/109 [==============================] - 12s 112ms/step - loss: 0.5961 - accuracy: 0.7675 - val_loss: 0.9863 - val_accuracy: 0.6607\n",
      "Epoch 40/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.5892 - accuracy: 0.7700\n",
      "Epoch 40: val_accuracy did not improve from 0.67267\n",
      "109/109 [==============================] - 12s 112ms/step - loss: 0.5892 - accuracy: 0.7700 - val_loss: 1.0297 - val_accuracy: 0.6420\n",
      "Epoch 41/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.5734 - accuracy: 0.7779\n",
      "Epoch 41: val_accuracy did not improve from 0.67267\n",
      "109/109 [==============================] - 12s 111ms/step - loss: 0.5734 - accuracy: 0.7779 - val_loss: 0.9755 - val_accuracy: 0.6680\n",
      "Epoch 42/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.5645 - accuracy: 0.7796\n",
      "Epoch 42: val_accuracy did not improve from 0.67267\n",
      "109/109 [==============================] - 12s 112ms/step - loss: 0.5645 - accuracy: 0.7796 - val_loss: 1.0097 - val_accuracy: 0.6593\n",
      "Epoch 43/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.7816\n",
      "Epoch 43: val_accuracy improved from 0.67267 to 0.68200, saving model to weights_lstm.hdf5\n",
      "109/109 [==============================] - 12s 111ms/step - loss: 0.5652 - accuracy: 0.7816 - val_loss: 0.9676 - val_accuracy: 0.6820\n",
      "Epoch 44/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.5518 - accuracy: 0.7895\n",
      "Epoch 44: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 110ms/step - loss: 0.5518 - accuracy: 0.7895 - val_loss: 0.9681 - val_accuracy: 0.6687\n",
      "Epoch 45/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.5202 - accuracy: 0.7970\n",
      "Epoch 45: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 111ms/step - loss: 0.5202 - accuracy: 0.7970 - val_loss: 0.9768 - val_accuracy: 0.6653\n",
      "Epoch 46/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.5272 - accuracy: 0.7964\n",
      "Epoch 46: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 111ms/step - loss: 0.5272 - accuracy: 0.7964 - val_loss: 1.0175 - val_accuracy: 0.6567\n",
      "Epoch 47/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.5178 - accuracy: 0.8030\n",
      "Epoch 47: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 112ms/step - loss: 0.5178 - accuracy: 0.8030 - val_loss: 0.9804 - val_accuracy: 0.6607\n",
      "Epoch 48/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4915 - accuracy: 0.8101\n",
      "Epoch 48: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 113ms/step - loss: 0.4915 - accuracy: 0.8101 - val_loss: 1.0132 - val_accuracy: 0.6600\n",
      "Epoch 49/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4923 - accuracy: 0.8124\n",
      "Epoch 49: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 116ms/step - loss: 0.4923 - accuracy: 0.8124 - val_loss: 1.0131 - val_accuracy: 0.6647\n",
      "Epoch 50/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4893 - accuracy: 0.8111\n",
      "Epoch 50: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 113ms/step - loss: 0.4893 - accuracy: 0.8111 - val_loss: 0.9748 - val_accuracy: 0.6747\n",
      "Epoch 51/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4573 - accuracy: 0.8259\n",
      "Epoch 51: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 111ms/step - loss: 0.4573 - accuracy: 0.8259 - val_loss: 1.0722 - val_accuracy: 0.6567\n",
      "Epoch 52/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4626 - accuracy: 0.8223\n",
      "Epoch 52: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 111ms/step - loss: 0.4626 - accuracy: 0.8223 - val_loss: 1.0272 - val_accuracy: 0.6640\n",
      "Epoch 53/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4741 - accuracy: 0.8178\n",
      "Epoch 53: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 113ms/step - loss: 0.4741 - accuracy: 0.8178 - val_loss: 1.0715 - val_accuracy: 0.6473\n",
      "Epoch 54/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4398 - accuracy: 0.8346\n",
      "Epoch 54: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 111ms/step - loss: 0.4398 - accuracy: 0.8346 - val_loss: 1.0764 - val_accuracy: 0.6573\n",
      "Epoch 55/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4525 - accuracy: 0.8256\n",
      "Epoch 55: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 114ms/step - loss: 0.4525 - accuracy: 0.8256 - val_loss: 1.0958 - val_accuracy: 0.6540\n",
      "Epoch 56/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4272 - accuracy: 0.8348\n",
      "Epoch 56: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 118ms/step - loss: 0.4272 - accuracy: 0.8348 - val_loss: 1.0664 - val_accuracy: 0.6500\n",
      "Epoch 57/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4274 - accuracy: 0.8366\n",
      "Epoch 57: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 114ms/step - loss: 0.4274 - accuracy: 0.8366 - val_loss: 1.0418 - val_accuracy: 0.6693\n",
      "Epoch 58/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4157 - accuracy: 0.8409\n",
      "Epoch 58: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 114ms/step - loss: 0.4157 - accuracy: 0.8409 - val_loss: 1.0285 - val_accuracy: 0.6727\n",
      "Epoch 59/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.4102 - accuracy: 0.8424\n",
      "Epoch 59: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.4102 - accuracy: 0.8424 - val_loss: 1.0184 - val_accuracy: 0.6687\n",
      "Epoch 60/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3995 - accuracy: 0.8460\n",
      "Epoch 60: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 114ms/step - loss: 0.3995 - accuracy: 0.8460 - val_loss: 1.0461 - val_accuracy: 0.6607\n",
      "Epoch 61/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3927 - accuracy: 0.8517\n",
      "Epoch 61: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.3927 - accuracy: 0.8517 - val_loss: 1.0489 - val_accuracy: 0.6627\n",
      "Epoch 62/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3932 - accuracy: 0.8550\n",
      "Epoch 62: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 115ms/step - loss: 0.3932 - accuracy: 0.8550 - val_loss: 1.1475 - val_accuracy: 0.6527\n",
      "Epoch 63/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3720 - accuracy: 0.8638\n",
      "Epoch 63: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.3720 - accuracy: 0.8638 - val_loss: 1.0681 - val_accuracy: 0.6680\n",
      "Epoch 64/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3467 - accuracy: 0.8707\n",
      "Epoch 64: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 115ms/step - loss: 0.3467 - accuracy: 0.8707 - val_loss: 1.0551 - val_accuracy: 0.6820\n",
      "Epoch 65/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3745 - accuracy: 0.8608\n",
      "Epoch 65: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 116ms/step - loss: 0.3745 - accuracy: 0.8608 - val_loss: 1.1252 - val_accuracy: 0.6507\n",
      "Epoch 66/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3585 - accuracy: 0.8672\n",
      "Epoch 66: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 116ms/step - loss: 0.3585 - accuracy: 0.8672 - val_loss: 1.0394 - val_accuracy: 0.6713\n",
      "Epoch 67/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3569 - accuracy: 0.8661\n",
      "Epoch 67: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.3569 - accuracy: 0.8661 - val_loss: 1.0589 - val_accuracy: 0.6720\n",
      "Epoch 68/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3508 - accuracy: 0.8662\n",
      "Epoch 68: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 115ms/step - loss: 0.3508 - accuracy: 0.8662 - val_loss: 1.0791 - val_accuracy: 0.6553\n",
      "Epoch 69/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3310 - accuracy: 0.8737\n",
      "Epoch 69: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 118ms/step - loss: 0.3310 - accuracy: 0.8737 - val_loss: 1.0970 - val_accuracy: 0.6520\n",
      "Epoch 70/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3248 - accuracy: 0.8780\n",
      "Epoch 70: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 116ms/step - loss: 0.3248 - accuracy: 0.8780 - val_loss: 1.0899 - val_accuracy: 0.6647\n",
      "Epoch 71/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3225 - accuracy: 0.8826\n",
      "Epoch 71: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.3225 - accuracy: 0.8826 - val_loss: 1.1332 - val_accuracy: 0.6640\n",
      "Epoch 72/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3007 - accuracy: 0.8908\n",
      "Epoch 72: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.3007 - accuracy: 0.8908 - val_loss: 1.1241 - val_accuracy: 0.6587\n",
      "Epoch 73/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.3071 - accuracy: 0.8905\n",
      "Epoch 73: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.3071 - accuracy: 0.8905 - val_loss: 1.1114 - val_accuracy: 0.6647\n",
      "Epoch 74/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2944 - accuracy: 0.8938\n",
      "Epoch 74: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 116ms/step - loss: 0.2944 - accuracy: 0.8938 - val_loss: 1.1520 - val_accuracy: 0.6573\n",
      "Epoch 75/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2956 - accuracy: 0.8894\n",
      "Epoch 75: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 119ms/step - loss: 0.2956 - accuracy: 0.8894 - val_loss: 1.1168 - val_accuracy: 0.6660\n",
      "Epoch 76/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2821 - accuracy: 0.9013\n",
      "Epoch 76: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 114ms/step - loss: 0.2821 - accuracy: 0.9013 - val_loss: 1.2163 - val_accuracy: 0.6533\n",
      "Epoch 77/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2872 - accuracy: 0.8927\n",
      "Epoch 77: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.2872 - accuracy: 0.8927 - val_loss: 1.1442 - val_accuracy: 0.6653\n",
      "Epoch 78/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2677 - accuracy: 0.9034\n",
      "Epoch 78: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 115ms/step - loss: 0.2677 - accuracy: 0.9034 - val_loss: 1.1702 - val_accuracy: 0.6753\n",
      "Epoch 79/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2672 - accuracy: 0.9006\n",
      "Epoch 79: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 118ms/step - loss: 0.2672 - accuracy: 0.9006 - val_loss: 1.1865 - val_accuracy: 0.6553\n",
      "Epoch 80/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.9056\n",
      "Epoch 80: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 115ms/step - loss: 0.2665 - accuracy: 0.9056 - val_loss: 1.1830 - val_accuracy: 0.6547\n",
      "Epoch 81/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2460 - accuracy: 0.9114\n",
      "Epoch 81: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.2460 - accuracy: 0.9114 - val_loss: 1.1733 - val_accuracy: 0.6587\n",
      "Epoch 82/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2398 - accuracy: 0.9112\n",
      "Epoch 82: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 116ms/step - loss: 0.2398 - accuracy: 0.9112 - val_loss: 1.1540 - val_accuracy: 0.6707\n",
      "Epoch 83/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2508 - accuracy: 0.9089\n",
      "Epoch 83: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 116ms/step - loss: 0.2508 - accuracy: 0.9089 - val_loss: 1.1934 - val_accuracy: 0.6533\n",
      "Epoch 84/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2445 - accuracy: 0.9132\n",
      "Epoch 84: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 116ms/step - loss: 0.2445 - accuracy: 0.9132 - val_loss: 1.1845 - val_accuracy: 0.6560\n",
      "Epoch 85/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2359 - accuracy: 0.9158\n",
      "Epoch 85: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 118ms/step - loss: 0.2359 - accuracy: 0.9158 - val_loss: 1.2325 - val_accuracy: 0.6520\n",
      "Epoch 86/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2249 - accuracy: 0.9167\n",
      "Epoch 86: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 115ms/step - loss: 0.2249 - accuracy: 0.9167 - val_loss: 1.2235 - val_accuracy: 0.6567\n",
      "Epoch 87/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2246 - accuracy: 0.9170\n",
      "Epoch 87: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 115ms/step - loss: 0.2246 - accuracy: 0.9170 - val_loss: 1.1824 - val_accuracy: 0.6633\n",
      "Epoch 88/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.9188\n",
      "Epoch 88: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.2221 - accuracy: 0.9188 - val_loss: 1.1831 - val_accuracy: 0.6633\n",
      "Epoch 89/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2201 - accuracy: 0.9208\n",
      "Epoch 89: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 115ms/step - loss: 0.2201 - accuracy: 0.9208 - val_loss: 1.2032 - val_accuracy: 0.6653\n",
      "Epoch 90/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2121 - accuracy: 0.9266\n",
      "Epoch 90: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 118ms/step - loss: 0.2121 - accuracy: 0.9266 - val_loss: 1.1855 - val_accuracy: 0.6767\n",
      "Epoch 91/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.9249\n",
      "Epoch 91: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 116ms/step - loss: 0.2152 - accuracy: 0.9249 - val_loss: 1.2124 - val_accuracy: 0.6553\n",
      "Epoch 92/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1987 - accuracy: 0.9293\n",
      "Epoch 92: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.1987 - accuracy: 0.9293 - val_loss: 1.2574 - val_accuracy: 0.6573\n",
      "Epoch 93/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1992 - accuracy: 0.9293\n",
      "Epoch 93: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 115ms/step - loss: 0.1992 - accuracy: 0.9293 - val_loss: 1.2209 - val_accuracy: 0.6647\n",
      "Epoch 94/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.9310\n",
      "Epoch 94: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.1884 - accuracy: 0.9310 - val_loss: 1.2988 - val_accuracy: 0.6560\n",
      "Epoch 95/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1952 - accuracy: 0.9289\n",
      "Epoch 95: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 12s 115ms/step - loss: 0.1952 - accuracy: 0.9289 - val_loss: 1.2349 - val_accuracy: 0.6740\n",
      "Epoch 96/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1929 - accuracy: 0.9310\n",
      "Epoch 96: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 118ms/step - loss: 0.1929 - accuracy: 0.9310 - val_loss: 1.2271 - val_accuracy: 0.6707\n",
      "Epoch 97/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1902 - accuracy: 0.9364\n",
      "Epoch 97: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 116ms/step - loss: 0.1902 - accuracy: 0.9364 - val_loss: 1.2640 - val_accuracy: 0.6627\n",
      "Epoch 98/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1823 - accuracy: 0.9384\n",
      "Epoch 98: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 117ms/step - loss: 0.1823 - accuracy: 0.9384 - val_loss: 1.2955 - val_accuracy: 0.6600\n",
      "Epoch 99/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1797 - accuracy: 0.9338\n",
      "Epoch 99: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 115ms/step - loss: 0.1797 - accuracy: 0.9338 - val_loss: 1.3410 - val_accuracy: 0.6440\n",
      "Epoch 100/100\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.9480\n",
      "Epoch 100: val_accuracy did not improve from 0.68200\n",
      "109/109 [==============================] - 13s 118ms/step - loss: 0.1554 - accuracy: 0.9480 - val_loss: 1.2893 - val_accuracy: 0.6653\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"weights_lstm.hdf5\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-4), metrics=[\"accuracy\"])\n",
    "lstm_history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=100, batch_size=64, callbacks=[model_checkpoint_callback])\n",
    "end = time.time()\n",
    "wall_time_lstm = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(lstm_history.history['accuracy'])\n",
    "plt.plot(lstm_history.history['val_accuracy'])\n",
    "plt.title('LSTM model accuracy trajectory')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(lstm_history.history['loss'],'o')\n",
    "plt.plot(lstm_history.history['val_loss'],'o')\n",
    "plt.title('LSTM model loss trajectory')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weights_lstm.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 1s 12ms/step - loss: 1.1637 - accuracy: 0.6106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.163666844367981, 0.6106094717979431]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy and Loss Trajectory - See CNN preprocessing notebook\n",
    "# Wall Time Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
